{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "cluster = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster:\n",
    "    wd_dir = '/beegfs/scratch/ric.broccoli/kubacki.michal/GSE98969'\n",
    "else:\n",
    "    wd_dir = '/home/michal/WSL_GitHub/SRF_microglia/GSE98969'\n",
    "os.chdir(wd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster:\n",
    "    sharon_dir = '/beegfs/scratch/ric.broccoli/kubacki.michal/Sharon_RNA/samples/all/runs/all/fastq/merge-by-read/trimmed/trimmomatic/mapped/STAR/merged/featureCounts/merged'\n",
    "else:\n",
    "    sharon_dir = '/home/michal/WSL_GitHub/SRF_microglia/data/sharon_rna'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "In addition: Warning message:\n",
       "In (function (package, help, pos = 2, lib.loc = NULL, character.only = FALSE,  :\n",
       "  libraries ‘/usr/local/lib/R/site-library’, ‘/usr/lib/R/site-library’ contain no packages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "x <- c(1, 2, 3, 4, 5)\n",
    "mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load GSE98969 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/extracted/GSM2629439_AB2434.txt.gz', './data/extracted/GSM2629424_AB2340.txt.gz', './data/extracted/GSM2629423_AB2339.txt.gz', './data/extracted/GSM2629445_AB2440.txt.gz', './data/extracted/GSM2629367_AB1710.txt.gz', './data/extracted/GSM2629398_AB1741.txt.gz', './data/extracted/GSM2629438_AB2433.txt.gz', './data/extracted/GSM2629342_AB1443.txt.gz', './data/extracted/GSM2629417_AB2333.txt.gz', './data/extracted/GSM2629373_AB1716.txt.gz', './data/extracted/GSM2629366_AB1709.txt.gz', './data/extracted/GSM2629397_AB1740.txt.gz', './data/extracted/GSM2629344_AB1445.txt.gz', './data/extracted/GSM2629356_AB1551.txt.gz', './data/extracted/GSM2629347_AB1448.txt.gz', './data/extracted/GSM2629441_AB2436.txt.gz', './data/extracted/GSM2629354_AB1549.txt.gz', './data/extracted/GSM2629437_AB2432.txt.gz', './data/extracted/GSM2629404_AB1863.txt.gz', './data/extracted/GSM2629414_AB2330.txt.gz', './data/extracted/GSM2629442_AB2437.txt.gz', './data/extracted/GSM2629360_AB1555.txt.gz', './data/extracted/GSM2629434_AB2429.txt.gz', './data/extracted/GSM2629368_AB1711.txt.gz', './data/extracted/GSM2629426_AB2342.txt.gz', './data/extracted/GSM2629435_AB2430.txt.gz', './data/extracted/GSM2629402_AB1745.txt.gz', './data/extracted/GSM2629405_AB1864.txt.gz', './data/extracted/GSM2629352_AB1547.txt.gz', './data/extracted/GSM2629446_AB2441.txt.gz', './data/extracted/GSM2629390_AB1733.txt.gz', './data/extracted/GSM2629392_AB1735.txt.gz', './data/extracted/GSM2629395_AB1738.txt.gz', './data/extracted/GSM2629399_AB1742.txt.gz', './data/extracted/GSM2629391_AB1734.txt.gz', './data/extracted/GSM2629427_AB2343.txt.gz', './data/extracted/GSM2629376_AB1719.txt.gz', './data/extracted/GSM2629365_AB1668.txt.gz', './data/extracted/GSM2629448_AB2443.txt.gz', './data/extracted/GSM2629361_AB1556.txt.gz', './data/extracted/GSM2629407_AB2323.txt.gz', './data/extracted/GSM2629389_AB1732.txt.gz', './data/extracted/GSM2629440_AB2435.txt.gz', './data/extracted/GSM2629358_AB1553.txt.gz', './data/extracted/GSM2629374_AB1717.txt.gz', './data/extracted/GSM2629341_AB1442.txt.gz', './data/extracted/GSM2629409_AB2325.txt.gz', './data/extracted/GSM2629431_AB2426.txt.gz', './data/extracted/GSM2629403_AB1746.txt.gz', './data/extracted/GSM2629396_AB1739.txt.gz', './data/extracted/GSM2629364_AB1667.txt.gz', './data/extracted/GSM2629348_AB1449.txt.gz', './data/extracted/GSM2629345_AB1446.txt.gz', './data/extracted/GSM2629370_AB1713.txt.gz', './data/extracted/GSM2629387_AB1730.txt.gz', './data/extracted/GSM2629362_AB1557.txt.gz', './data/extracted/GSM2629357_AB1552.txt.gz', './data/extracted/GSM2629422_AB2338.txt.gz', './data/extracted/GSM2629388_AB1731.txt.gz', './data/extracted/GSM2629346_AB1447.txt.gz', './data/extracted/GSM2629359_AB1554.txt.gz', './data/extracted/GSM2629355_AB1550.txt.gz', './data/extracted/GSM2629343_AB1444.txt.gz', './data/extracted/GSM2629418_AB2334.txt.gz', './data/extracted/GSM2629430_AB2425.txt.gz', './data/extracted/GSM2629443_AB2438.txt.gz', './data/extracted/GSM2629419_AB2335.txt.gz', './data/extracted/GSM2629401_AB1744.txt.gz', './data/extracted/GSM2629421_AB2337.txt.gz', './data/extracted/GSM2629425_AB2341.txt.gz', './data/extracted/GSM2629420_AB2336.txt.gz', './data/extracted/GSM2629377_AB1720.txt.gz', './data/extracted/GSM2629363_AB1558.txt.gz', './data/extracted/GSM2629369_AB1712.txt.gz', './data/extracted/GSM2629433_AB2428.txt.gz', './data/extracted/GSM2629410_AB2326.txt.gz', './data/extracted/GSM2629394_AB1737.txt.gz', './data/extracted/GSM2629432_AB2427.txt.gz', './data/extracted/GSM2629447_AB2442.txt.gz', './data/extracted/GSM2629412_AB2328.txt.gz', './data/extracted/GSM2629449_AB2444.txt.gz', './data/extracted/GSM2629416_AB2332.txt.gz', './data/extracted/GSM2629400_AB1743.txt.gz', './data/extracted/GSM2629415_AB2331.txt.gz', './data/extracted/GSM2629408_AB2324.txt.gz', './data/extracted/GSM2629375_AB1718.txt.gz', './data/extracted/GSM2629413_AB2329.txt.gz', './data/extracted/GSM2629406_AB2322.txt.gz', './data/extracted/GSM2629393_AB1736.txt.gz', './data/extracted/GSM2629372_AB1715.txt.gz', './data/extracted/GSM2629411_AB2327.txt.gz', './data/extracted/GSM2629436_AB2431.txt.gz', './data/extracted/GSM2629429_AB2345.txt.gz', './data/extracted/GSM2629428_AB2344.txt.gz', './data/extracted/GSM2629444_AB2439.txt.gz', './data/extracted/GSM2629353_AB1548.txt.gz', './data/extracted/GSM2629371_AB1714.txt.gz']\n"
     ]
    }
   ],
   "source": [
    "# Get list of all MARS-seq files\n",
    "mars_seq_files = glob('./data/extracted/GSM*.txt.gz')\n",
    "print(mars_seq_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Treatment': \"treatment: Alzheimer's disease\",\n",
       " 'age': 'mouse age: 6 months',\n",
       " 'region': 'Whole brain',\n",
       " 'title': 'AB1442',\n",
       " 'strain': 'strain: 5XFAD',\n",
       " 'organ': 'organ: Brain'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read metadata\n",
    "metadata = pd.read_csv('./data/metadata_csv.csv')\n",
    "metadata_dict = metadata.set_index('geo_accession').to_dict('index')\n",
    "metadata_dict[list(metadata_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mars_seq_file_in_chunks(filename, chunksize=10000):\n",
    "    total_rows = sum(1 for _ in pd.read_csv(filename, sep='\\t', compression='gzip', chunksize=chunksize))\n",
    "    \n",
    "    pbar = tqdm(total=total_rows, desc=\"Reading file\", unit=\"rows\")\n",
    "    for chunk in pd.read_csv(filename, sep='\\t', compression='gzip', index_col=0, chunksize=chunksize):\n",
    "        pbar.update(len(chunk))\n",
    "        yield chunk\n",
    "    pbar.close()\n",
    "\n",
    "def process_mars_seq_files(mars_seq_files, metadata_dict, chunksize=10000):\n",
    "    adata = None\n",
    "    obs_names_counter = {}\n",
    "    \n",
    "    for file in tqdm(mars_seq_files, desc=\"Processing files\", unit=\"file\"):\n",
    "        print(f\"\\nProcessing file: {file}\")\n",
    "        gsm_id = os.path.basename(file).split('_')[0]\n",
    "        \n",
    "        for i, chunk in enumerate(read_mars_seq_file_in_chunks(file, chunksize)):\n",
    "            # Make observation names unique within the file\n",
    "            chunk.index = [f\"{gsm_id}_{idx}\" for idx in chunk.index]\n",
    "            \n",
    "            # Ensure observation names are unique across all files\n",
    "            new_obs_names = []\n",
    "            for name in chunk.index:\n",
    "                if name in obs_names_counter:\n",
    "                    obs_names_counter[name] += 1\n",
    "                    new_name = f\"{name}_{obs_names_counter[name]}\"\n",
    "                else:\n",
    "                    obs_names_counter[name] = 0\n",
    "                    new_name = name\n",
    "                new_obs_names.append(new_name)\n",
    "            \n",
    "            chunk.index = new_obs_names\n",
    "            \n",
    "            current_adata = ad.AnnData(chunk.T)\n",
    "            \n",
    "            # Add metadata\n",
    "            if gsm_id in metadata_dict:\n",
    "                for key, value in metadata_dict[gsm_id].items():\n",
    "                    current_adata.obs[key] = value\n",
    "            else:\n",
    "                print(f\"Warning: No metadata found for {gsm_id}\")\n",
    "            \n",
    "            if adata is None:\n",
    "                adata = current_adata\n",
    "            else:\n",
    "                adata = ad.concat([adata, current_adata], join='outer', fill_value=0)\n",
    "            \n",
    "            # Clear temporary variables\n",
    "            del chunk, current_adata\n",
    "            gc.collect()\n",
    "        \n",
    "        gc.collect()\n",
    "    \n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/97 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: ./data/extracted/GSM2629439_AB2434.txt.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "Reading file: 34016rows [00:01, 31031.27rows/s]\n",
      "Processing files:   1%|          | 1/97 [00:01<02:26,  1.52s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: ./data/extracted/GSM2629424_AB2340.txt.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "Reading file: 34016rows [00:02, 11475.31rows/s]\n",
      "Processing files:   2%|▏         | 2/97 [00:04<04:09,  2.62s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: ./data/extracted/GSM2629423_AB2339.txt.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "Reading file: 34016rows [00:07, 4364.68rows/s]\n",
      "Processing files:   3%|▎         | 3/97 [00:13<08:08,  5.19s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: ./data/extracted/GSM2629445_AB2440.txt.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/home/michal/miniconda3/envs/snakemake-tutorial/lib/python3.12/site-packages/anndata/_core/anndata.py:1754: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "adata = process_mars_seq_files(mars_seq_files, metadata_dict)\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all MARS-seq files and store them in a list\n",
    "adatas = []\n",
    "for file in mars_seq_files:\n",
    "    df = read_mars_seq_file(file)\n",
    "    adata = ad.AnnData(df.T)\n",
    "    adata.var_names_make_unique()\n",
    "    \n",
    "    # Extract GSM ID from filename\n",
    "    gsm_id = os.path.basename(file).split('_')[0]\n",
    "    \n",
    "    # Add metadata\n",
    "    if gsm_id in metadata_dict:\n",
    "        for key, value in metadata_dict[gsm_id].items():\n",
    "            adata.obs[key] = value\n",
    "    else:\n",
    "        print(f\"Warning: No metadata found for {gsm_id}\")\n",
    "    \n",
    "    adatas.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all AnnData objects\n",
    "# adata = ad.concat(adatas, join='outer', fill_value=0)\n",
    "# adata\n",
    "\n",
    "# Initialize with the first AnnData object\n",
    "adata = adatas[0]\n",
    "\n",
    "# Iterate through the rest of the AnnData objects\n",
    "for i in range(1, len(adatas)):\n",
    "    # Perform outer join with current adata\n",
    "    adata = ad.concat([adata, adatas[i]], join='outer', fill_value=0)\n",
    "    \n",
    "    # Clear the individual AnnData object to free up memory\n",
    "    adatas[i] = None\n",
    "    \n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "# Clear the list of individual AnnData objects\n",
    "adatas = None\n",
    "gc.collect()\n",
    "\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove prefixes\n",
    "adata.obs['Treatment'] = adata.obs['Treatment'].str.replace('treatment: ', '')\n",
    "adata.obs['age'] = adata.obs['age'].str.replace('mouse age: ', '')\n",
    "adata.obs['strain'] = adata.obs['strain'].str.replace('strain: ', '')\n",
    "adata.obs['organ'] = adata.obs['organ'].str.replace('organ: ', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quality control metrics\n",
    "adata.var['mt'] = adata.var_names.str.startswith('mt-')  # Identify mitochondrial genes\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot QC metrics\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0.4, multi_panel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter cells based on QC metrics (adjust these thresholds as needed)\n",
    "adata = adata[adata.obs.n_genes_by_counts < 3000, :]\n",
    "adata = adata[adata.obs.total_counts < 10000, :]\n",
    "adata = adata[adata.obs.pct_counts_mt < 20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot QC metrics\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], jitter=0.4, multi_panel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw counts in a new layer\n",
    "adata.layers['counts'] = adata.X.copy()\n",
    "\n",
    "# Normalize data\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly variable genes\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "\n",
    "# Plot highly variable genes\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the .raw attribute of AnnData object to the normalized and logarithmized raw gene expression\n",
    "adata.raw = adata\n",
    "\n",
    "# Scale data\n",
    "sc.pp.scale(adata, max_value=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "\n",
    "# Compute neighborhood graph\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform UMAP Embedding\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP\n",
    "sc.pl.umap(adata, color=['Treatment', 'age', 'region', 'strain', 'organ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "sc.tl.leiden(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clustering results\n",
    "sc.pl.umap(adata, color=['leiden', 'Treatment', 'age', 'region', 'strain', 'organ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Find marker genes\n",
    "sc.tl.rank_genes_groups(adata, 'leiden', method='t-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "adata.write('./output/GSE98969_microglia_results.h5ad')\n",
    "\n",
    "print(\"Analysis complete. Results saved to 'GSE98969_microglia_results.h5ad'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load the saved results.\"\"\"\n",
    "    adata = sc.read(file_path)\n",
    "    print(f\"Data loaded successfully. Shape: {adata.shape}\")\n",
    "    print(f\"Observations: {list(adata.obs_keys())}\")\n",
    "    print(f\"Variables: {list(adata.var_keys())}\")\n",
    "    return adata\n",
    "\n",
    "def prepare_data(adata):\n",
    "    \"\"\"Prepare the data for analysis.\"\"\"\n",
    "    adata.layers['log_norm'] = adata.X.copy()\n",
    "    adata.X = adata.layers['counts'].copy()\n",
    "    return adata\n",
    "\n",
    "def create_pseudobulk(adata, group_by):\n",
    "    \"\"\"Create pseudo-bulk data from single-cell data.\"\"\"\n",
    "    adata.obs[group_by] = pd.Categorical(adata.obs[group_by])\n",
    "    indicator = pd.get_dummies(adata.obs[group_by])\n",
    "    \n",
    "    pseudobulk = ad.AnnData(\n",
    "        X=indicator.values.T @ adata.X,\n",
    "        obs=pd.DataFrame(index=indicator.columns),\n",
    "        var=adata.var.copy()\n",
    "    )\n",
    "    \n",
    "    pseudobulk.obs = adata.obs.groupby(group_by).first()\n",
    "    \n",
    "    for layer in adata.layers.keys():\n",
    "        pseudobulk.layers[layer] = indicator.values.T @ adata.layers[layer]\n",
    "    \n",
    "    return pseudobulk\n",
    "\n",
    "def normalize_pseudobulk(pseudobulk):\n",
    "    \"\"\"Normalize pseudo-bulk data.\"\"\"\n",
    "    pseudobulk_norm = pseudobulk.copy()\n",
    "    pseudobulk_norm.X = pseudobulk_norm.X / pseudobulk_norm.X.sum(axis=1, keepdims=True) * 1e6\n",
    "    pseudobulk_norm.layers['counts'] = pseudobulk_norm.layers['counts'] / pseudobulk_norm.layers['counts'].sum(axis=1, keepdims=True) * 1e6\n",
    "    pseudobulk_norm.layers['log_norm'] = np.log1p(pseudobulk_norm.X)\n",
    "    return pseudobulk_norm\n",
    "\n",
    "def log_transform(pseudobulk_norm):\n",
    "    \"\"\"Log transform the normalized data.\"\"\"\n",
    "    pseudobulk_log = pseudobulk_norm.copy()\n",
    "    pseudobulk_log.X = np.log2(pseudobulk_log.X + 1)\n",
    "    return pseudobulk_log\n",
    "\n",
    "def perform_de(adata, group1, group2, min_samples=3):\n",
    "    \"\"\"\n",
    "    Perform differential expression analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - adata: AnnData object\n",
    "    - group1, group2: lists of sample names for each group\n",
    "    - min_samples: minimum number of samples required in each group to perform t-test\n",
    "    \"\"\"\n",
    "    genes = []\n",
    "    pvalues = []\n",
    "    log2fc = []\n",
    "    \n",
    "    for gene in adata.var_names:\n",
    "        group1_data = adata[:, gene].X[adata.obs.index.isin(group1)].flatten()\n",
    "        group2_data = adata[:, gene].X[adata.obs.index.isin(group2)].flatten()\n",
    "        \n",
    "        # Remove zero values\n",
    "        group1_data = group1_data[group1_data != 0]\n",
    "        group2_data = group2_data[group2_data != 0]\n",
    "        \n",
    "        # Check if we have enough non-zero samples\n",
    "        if len(group1_data) >= min_samples and len(group2_data) >= min_samples:\n",
    "            # Perform t-test\n",
    "            t_stat, p_value = stats.ttest_ind(group1_data, group2_data)\n",
    "            \n",
    "            # Calculate log2 fold change\n",
    "            mean1 = np.mean(group1_data) if len(group1_data) > 0 else 1e-9\n",
    "            mean2 = np.mean(group2_data) if len(group2_data) > 0 else 1e-9\n",
    "            log2fc_value = np.log2(mean1 / mean2)\n",
    "            \n",
    "            genes.append(gene)\n",
    "            pvalues.append(p_value)\n",
    "            log2fc.append(log2fc_value)\n",
    "        else:\n",
    "            # If not enough samples, add NaN values\n",
    "            genes.append(gene)\n",
    "            pvalues.append(np.nan)\n",
    "            log2fc.append(np.nan)\n",
    "    \n",
    "    return pd.DataFrame({'gene': genes, 'pvalue': pvalues, 'log2fc': log2fc})\n",
    "\n",
    "def plot_volcano(de_results):\n",
    "    \"\"\"Create and save a volcano plot.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(de_results['log2fc'], -np.log10(de_results['pvalue']), alpha=0.5)\n",
    "    plt.xlabel('Log2 Fold Change')\n",
    "    plt.ylabel('-Log10 P-value')\n",
    "    plt.title('Volcano Plot: 5XFAD vs C57BL/6')\n",
    "    plt.show()\n",
    "\n",
    "def plot_heatmap(adata, genes):\n",
    "    \"\"\"Create and save a heatmap of top differentially expressed genes.\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sc.pl.heatmap(adata, var_names=genes, groupby='strain', show_gene_labels=True, cmap='viridis', dendrogram=False)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def save_results(pseudobulk, pseudobulk_norm, pseudobulk_log, de_results):\n",
    "    \"\"\"Save analysis results to CSV files.\"\"\"\n",
    "    pseudobulk.write_csvs('pseudobulk_raw_counts.csv')\n",
    "    pseudobulk_norm.write_csvs('pseudobulk_normalized.csv')\n",
    "    pd.DataFrame(pseudobulk_log.X.T, index=pseudobulk_log.var_names, columns=pseudobulk_log.obs_names).to_csv('pseudobulk_log_transformed.csv')\n",
    "    de_results.to_csv('differential_expression_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "adata = load_data('./output/GSE98969_microglia_results.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = prepare_data(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and process pseudo-bulk data\n",
    "pseudobulk = create_pseudobulk(adata, 'strain')\n",
    "pseudobulk_norm = normalize_pseudobulk(pseudobulk)\n",
    "pseudobulk_log = log_transform(pseudobulk_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform differential expression analysis\n",
    "de_results = perform_de(pseudobulk_log, ['5XFAD'], ['C57BL/6'])\n",
    "de_results = de_results.sort_values('pvalue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_volcano(de_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_heatmap(pseudobulk_log, de_results.head(50)['gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pseudo-bulk data\n",
    "def create_pseudobulk(adata, group_by):\n",
    "    \"\"\"\n",
    "    This function creates pseudo-bulk data from single-cell data.\n",
    "    \n",
    "    Parameters:\n",
    "    - adata: AnnData object containing single-cell data\n",
    "    - group_by: String, the column name in adata.obs to group cells by\n",
    "    \n",
    "    The function does the following:\n",
    "    1. Converts the grouping column to categorical data type.\n",
    "    2. Creates an indicator matrix for each group.\n",
    "    3. Sums the counts for each group to create pseudo-bulk data.\n",
    "    4. Maintains relevant metadata from the original data.\n",
    "    5. Preserves all layers from the original data in the pseudo-bulk data.\n",
    "    \n",
    "    Returns:\n",
    "    - pseudobulk: AnnData object containing the pseudo-bulk data\n",
    "    \"\"\"\n",
    "    # Convert group_by column to categorical if it's not already\n",
    "    adata.obs[group_by] = pd.Categorical(adata.obs[group_by])\n",
    "    \n",
    "    # Create indicator matrix\n",
    "    indicator = pd.get_dummies(adata.obs[group_by])\n",
    "    \n",
    "    # Sum the counts for each group\n",
    "    pseudobulk = ad.AnnData(\n",
    "        X=indicator.values.T @ adata.X,\n",
    "        obs=pd.DataFrame(index=indicator.columns),\n",
    "        var=adata.var.copy()\n",
    "    )\n",
    "    \n",
    "    # Maintain relevant metadata\n",
    "    pseudobulk.obs = adata.obs.groupby(group_by).first()\n",
    "    \n",
    "    # Ensure the layers are preserved\n",
    "    for layer in adata.layers.keys():\n",
    "        pseudobulk.layers[layer] = indicator.values.T @ adata.layers[layer]\n",
    "    \n",
    "    return pseudobulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudobulk = create_pseudobulk(adata, 'strain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudobulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudobulk.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize pseudo-bulk data\n",
    "# pseudobulk_norm = pseudobulk.copy()\n",
    "# pseudobulk_norm.X = pseudobulk_norm.X / pseudobulk_norm.X.sum(axis=1, keepdims=True) * 1e6  # CPM normalization\n",
    "# pseudobulk_norm.layers['counts'] = pseudobulk_norm.layers['counts'] / pseudobulk_norm.layers['counts'].sum(axis=1, keepdims=True) * 1e6  # CPM normalization for counts layer\n",
    "# pseudobulk_norm.layers['log_norm'] = np.log1p(pseudobulk_norm.X)  # Log-normalize the main matrix\n",
    "# pseudobulk_norm.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform\n",
    "pseudobulk_log = np.log2(pseudobulk_norm + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudobulk_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('pseudobulk_log.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# Create AnnData object\n",
    "adata = sc.AnnData(data.T)\n",
    "\n",
    "# Add gene names to var\n",
    "adata.var_names = data.index\n",
    "\n",
    "# Add condition information to obs\n",
    "adata.obs['condition'] = adata.obs.index\n",
    "\n",
    "# Perform differential expression analysis\n",
    "sc.tl.rank_genes_groups(adata, 'condition', method='wilcoxon')\n",
    "\n",
    "# Get results\n",
    "results = adata.uns['rank_genes_groups']\n",
    "groups = results['names'].dtype.names\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "def get_df(key):\n",
    "    return pd.DataFrame({group + '_' + key: results[key][group] for group in groups})\n",
    "\n",
    "results_df = pd.concat([get_df(key) for key in ['names', 'scores', 'pvals', 'pvals_adj']], axis=1)\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('differential_expression_results.csv')\n",
    "\n",
    "# Visualize top differentially expressed genes\n",
    "sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)\n",
    "plt.savefig('top_differentially_expressed_genes.png')\n",
    "\n",
    "# Create a heatmap of top differentially expressed genes\n",
    "top_genes = results_df.iloc[:50, results_df.columns.get_level_values(1)=='names'].values.flatten()\n",
    "sc.pl.heatmap(adata, top_genes, groupby='condition', show_gene_labels=True, figsize=(12, 8))\n",
    "plt.savefig('heatmap_top_differentially_expressed_genes.png')\n",
    "\n",
    "print(\"Differential expression analysis completed. Results saved to 'differential_expression_results.csv'\")\n",
    "print(\"Visualizations saved as 'top_differentially_expressed_genes.png' and 'heatmap_top_differentially_expressed_genes.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform differential expression analysis\n",
    "def perform_de(data, group1, group2):\n",
    "    genes = []\n",
    "    pvalues = []\n",
    "    log2fc = []\n",
    "    for gene in data.index:\n",
    "        t_stat, p_value = stats.ttest_ind(data.loc[gene, group1], data.loc[gene, group2])\n",
    "        genes.append(gene)\n",
    "        pvalues.append(p_value)\n",
    "        log2fc.append(np.log2(data.loc[gene, group1].mean() / data.loc[gene, group2].mean()))\n",
    "    return pd.DataFrame({'gene': genes, 'pvalue': pvalues, 'log2fc': log2fc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Differential expression between 5XFAD and C57BL/6\n",
    "de_results = perform_de(pseudobulk_log, ['5XFAD'], ['C57BL/6'])\n",
    "de_results = de_results.sort_values('pvalue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volcano plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(de_results['log2fc'], -np.log10(de_results['pvalue']), alpha=0.5)\n",
    "plt.xlabel('Log2 Fold Change')\n",
    "plt.ylabel('-Log10 P-value')\n",
    "plt.title('Volcano Plot: 5XFAD vs C57BL/6')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap of top differentially expressed genes\n",
    "top_genes = de_results.head(50)['gene']\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(pseudobulk_log.loc[top_genes], cmap='viridis', center=0)\n",
    "plt.title('Top 50 Differentially Expressed Genes')\n",
    "plt.show()\n",
    "\n",
    "# Save pseudo-bulk data\n",
    "pseudobulk.to_csv('pseudobulk_raw_counts.csv')\n",
    "pseudobulk_norm.to_csv('pseudobulk_normalized.csv')\n",
    "pseudobulk_log.to_csv('pseudobulk_log_transformed.csv')\n",
    "de_results.to_csv('differential_expression_results.csv')\n",
    "\n",
    "print(\"Pseudo-bulk analysis complete. Results saved to CSV files and plots.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snakemake-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
